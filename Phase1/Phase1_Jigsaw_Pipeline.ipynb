{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba13671",
   "metadata": {},
   "source": [
    "# Phase 1: Jigsaw Puzzle Preprocessing Pipeline\n",
    "\n",
    "This notebook implements the full classical computer vision pipeline for preprocessing jigsaw puzzle images according to the project requirements. It includes:\n",
    "\n",
    "- Color normalization\n",
    "- Denoising\n",
    "- Edge enhancement\n",
    "- Foreground segmentation\n",
    "- Contour extraction\n",
    "- Cropping of individual pieces\n",
    "- Saving all artifacts for Milestone 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ee9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img, cmap='gray', title='', size=8):\n",
    "    plt.figure(figsize=(size, size))\n",
    "    if img.ndim == 2:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE = \"dataset_images/sample.jpg\"  # Replace with your actual image path\n",
    "OUTPUT_DIR = \"phase1_outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92241e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_normalize_clahe(img_bgr):\n",
    "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l2 = clahe.apply(l)\n",
    "    lab2 = cv2.merge((l2, a, b))\n",
    "    return cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def denoise_image(img_bgr):\n",
    "    return cv2.bilateralFilter(img_bgr, 9, 75, 75)\n",
    "\n",
    "def edge_enhance(img_bgr):\n",
    "    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gaussian = cv2.GaussianBlur(img_gray, (0, 0), sigmaX=3)\n",
    "    unsharp = cv2.addWeighted(img_gray, 1.5, gaussian, -0.5, 0)\n",
    "    return cv2.cvtColor(unsharp, cv2.COLOR_GRAY2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb57306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mask(img_bgr):\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    th = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                               cv2.THRESH_BINARY_INV, 51, 8)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "    closed = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5)), iterations=1)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(opened, connectivity=8)\n",
    "    mask = np.zeros_like(opened)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= 1000:\n",
    "            mask[labels == i] = 255\n",
    "    return mask\n",
    "\n",
    "def extract_contours(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return [c for c in contours if cv2.contourArea(c) >= 1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09926a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(INPUT_IMAGE)\n",
    "imshow(img, title=\"Original\")\n",
    "\n",
    "img_clahe = color_normalize_clahe(img)\n",
    "imshow(img_clahe, title=\"CLAHE Normalized\")\n",
    "\n",
    "img_denoised = denoise_image(img_clahe)\n",
    "imshow(img_denoised, title=\"Denoised\")\n",
    "\n",
    "img_sharp = edge_enhance(img_denoised)\n",
    "imshow(img_sharp, title=\"Edge Enhanced\")\n",
    "\n",
    "mask = compute_mask(img_denoised)\n",
    "imshow(mask, title=\"Mask\")\n",
    "\n",
    "contours = extract_contours(mask)\n",
    "img_contour = img.copy()\n",
    "cv2.drawContours(img_contour, contours, -1, (0,255,0), 2)\n",
    "imshow(img_contour, title=\"Contours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cropped_pieces(img, contours, out_dir, prefix=\"piece\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for i, cnt in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        pad = int(0.05 * max(w, h))\n",
    "        x0 = max(0, x - pad)\n",
    "        y0 = max(0, y - pad)\n",
    "        x1 = min(img.shape[1], x + w + pad)\n",
    "        y1 = min(img.shape[0], y + h + pad)\n",
    "        crop = img[y0:y1, x0:x1].copy()\n",
    "        filename = os.path.join(out_dir, f\"{prefix}_{i:02d}.png\")\n",
    "        cv2.imwrite(filename, crop)\n",
    "\n",
    "save_cropped_pieces(img, contours, os.path.join(OUTPUT_DIR, \"pieces\"))\n",
    "print(f\"Saved {len(contours)} pieces to {OUTPUT_DIR}/pieces/\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
